% !TeX spellcheck = sv_SE
\section{Matematisk modell}
\label{sec:modell}

Centralt i vår metod är en minsta-kvadratanpassning. Det är ett verktyg för att anpassa en funktion $f(x)$ med okända parametrar till mätdata $(x_i, y_i)$ på \emph{bästa sätt}. I detta fall betyder \emph{bästa sätt} att kvadratsumman av residualerna $r$ minimeras. Residualerna $r_i$ definieras som skillnaden mellan datan $y_i$ och det framtagna funktionsvärdet $f(x_i)$ enligt
\begin{equation}
r_i = y_i - f(x_i)
\end{equation} 

I vårt fall vill vi anpassa ett polynom av grad $n$ till datan. Funktionen $f(x)$ har då formen
\begin{equation}
f(x) = a_0 + a_1x + \dots a_n x^n
\end{equation}
och vi har därför $n + 1$ parametrar att bestämma. Kvadratsumman av residualerna kan då skrivas som
\begin{equation}
F(\mathbf{a}) = \sum_{i} (y_i - f(x_i))^2 = \sum_i (y_i - (a_0 + a_1x_i + \dots + a_n x_i^n)^2
\end{equation}
Nödvändigt villkor för minimum är $\partial F/\partial a_j = 0$. Detta ger oss $n + 1$ ekvationer för $n + 1$ okända.
\begin{align}
    \frac{\partial F}{\partial a_0} &= \sum_i \left[ 2(y_i - (a_0 + a_1x_i + \dots + a_n x_i^n))(-1) \right] = 0 \\
    \frac{\partial F}{\partial a_1} &= \sum_i \left[ 2(y_i - (a_0 + a_1x_i + \dots + a_n x_i^n))(-x_i) \right] = 0 \\
    \vdots \\
    \frac{\partial F}{\partial a_n} &= \sum_i \left[ 2(y_i - (a_0 + a_1x_i + \dots + a_n x_i^n))(-x_i^n) \right] = 0
\end{align}
Vi kan skriva om dem som
\begin{align}
a_0 \sum_i 1 + a_1 \sum_i x_i + \dots + a_n \sum x_i^n &= \sum_i y_i \\
a_0 \sum_i x_i + a_1 \sum_i x_i^2 + \dots + a_n \sum x_i^{n+1} &= \sum_i x_i y_i \\
\vdots \\
a_0 \sum_i x_i^n + a_1 \sum_i x_i^{n+1} + \dots + a_n \sum x_i^{2n} &= \sum_i x_i^n y_i
\end{align}
Eller på matrisform
\begin{equation}
\begin{bmatrix}
\sum 1 & \dots & \sum x_i^n \\
\vdots & \ddots & \vdots \\
\sum x_i^n & \dots & \sum x_i^{2n}
\end{bmatrix}
\begin{bmatrix}
a_0 \\
\vdots \\
a_n
\end{bmatrix} = \begin{bmatrix}
\sum y_i \\
\vdots \\
\sum x_i^n y_i
\end{bmatrix}
\label{eqn:ls}
\end{equation}
som är ett enkelt system och lätt att lösa.

\subsection{Val av polynomgrad}

Vi är fria att välja vilken grad av polynom vi vill, förutsatt att graden $n$ uppfyller $n \leq m-1$ för antal datapunkter $m$. Vid likhet behövs ingen minsta-kvadratanpassning, utan lösningen är exakt.

Enligt \cite{ref:kaw} bör vi välja den grad som minimerar variansen
\begin{equation}
\frac{\operatorname{Sr}(n)}{m-n-1}
\label{eqn:kaw}
\end{equation}
för kvadratsumman av residualerna $\operatorname{Sr}(n)$.

